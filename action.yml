name: 'ReviewPal'
description: 'AI-powered code review for any language using Gemini'
author: 'Han Kim'

branding:
  icon: 'eye'
  color: 'purple'

inputs:
  gemini_api_key:
    description: 'Google Gemini API key (REQUIRED)'
    required: true
  github_token:
    description: 'GitHub token for posting comments (defaults to GITHUB_TOKEN)'
    required: false
    default: ${{ github.token }}
  model:
    description: 'Gemini model to use'
    required: false
    default: 'gemini-2.5-pro'
  max_api_calls:
    description: 'Maximum API calls (1 triage + N deep reviews + 3 adversarial)'
    required: false
    default: '10'
  comment_on_pr:
    description: 'Post analysis as PR comment'
    required: false
    default: 'true'
  format:
    description: 'Output format: friendly, json'
    required: false
    default: 'friendly'

outputs:
  total_files:
    description: 'Number of files analyzed'
  total_hunks:
    description: 'Number of hunks reviewed'
  verdict:
    description: 'Review verdict: BLOCK, WARN, or CLEAR'
  analysis_markdown:
    description: 'Full analysis in markdown format'

runs:
  using: 'composite'
  steps:
    - name: Setup Node.js
      uses: actions/setup-node@v4
      with:
        node-version: '20'
    
    - name: Install dependencies
      shell: bash
      run: |
        cd ${{ github.action_path }}
        npm ci --production
    
    - name: Build
      shell: bash
      run: |
        cd ${{ github.action_path }}
        npm run build
    
    - name: Get PR diff
      shell: bash
      id: diff
      run: |
        git fetch origin ${{ github.base_ref }} --depth=1
        git diff origin/${{ github.base_ref }}...HEAD > /tmp/pr.diff
        echo "diff_file=/tmp/pr.diff" >> $GITHUB_OUTPUT
        echo "lines=$(wc -l < /tmp/pr.diff)" >> $GITHUB_OUTPUT
    
    - name: Skip if no diff
      if: steps.diff.outputs.lines == '0'
      shell: bash
      run: |
        echo "No changes detected, skipping analysis"
        echo "total_files=0" >> $GITHUB_OUTPUT
        echo "total_hunks=0" >> $GITHUB_OUTPUT
        exit 0
    
    - name: Run analysis
      shell: bash
      id: analyze
      env:
        GEMINI_API_KEY: ${{ inputs.gemini_api_key }}
        GITHUB_TOKEN: ${{ inputs.github_token }}
        GH_TOKEN: ${{ inputs.github_token }}
        GITHUB_REPOSITORY: ${{ github.repository }}
        GITHUB_WORKSPACE: ${{ github.workspace }}
        PR_NUMBER: ${{ github.event.pull_request.number }}
        HEAD_SHA: ${{ github.event.pull_request.head.sha }}
      run: |
        cd ${{ github.action_path }}

        # Run analysis (quiet mode to hide spinner)
        node dist/index.js ${{ steps.diff.outputs.diff_file }} \
          --format ${{ inputs.format }} \
          --quiet \
          --repo-root "$GITHUB_WORKSPACE" \
          --model ${{ inputs.model }} \
          --max-api-calls ${{ inputs.max_api_calls }} > /tmp/analysis.md 2>&1 || true

        # Export for outputs
        echo "analysis_markdown<<EOF" >> $GITHUB_OUTPUT
        cat /tmp/analysis.md >> $GITHUB_OUTPUT
        echo "EOF" >> $GITHUB_OUTPUT

        # Also run JSON for structured data
        node dist/index.js ${{ steps.diff.outputs.diff_file }} \
          --format json \
          --quiet \
          --repo-root "$GITHUB_WORKSPACE" \
          --model ${{ inputs.model }} \
          --max-api-calls ${{ inputs.max_api_calls }} > /tmp/analysis.json 2>&1 || echo '{"files":[],"totalHunks":0}' > /tmp/analysis.json

        # Extract key metrics safely
        echo "total_files=$(jq '.files | length // 0' /tmp/analysis.json)" >> $GITHUB_OUTPUT
        echo "total_hunks=$(jq '.totalHunks // 0' /tmp/analysis.json)" >> $GITHUB_OUTPUT
        echo "verdict=$(jq -r '.verdict.verdict // "CLEAR"' /tmp/analysis.json)" >> $GITHUB_OUTPUT
    
    - name: Post inline comments and summary
      if: inputs.comment_on_pr == 'true' && github.event_name == 'pull_request' && steps.analyze.outputs.total_hunks != '0'
      uses: actions/github-script@v7
      with:
        github-token: ${{ inputs.github_token }}
        script: |
          const fs = require('fs');
          const analysisJson = JSON.parse(fs.readFileSync('/tmp/analysis.json', 'utf8'));
          
          const EMOJI_MAP = {
            security: 'ðŸ”’',
            crash: 'ðŸ’¥',
            'data-loss': 'ðŸ—‘ï¸',
            performance: 'ðŸŒ',
            regression: 'ðŸ”„',
            logic: 'ðŸ§©'
          };

          const VERDICT_EMOJI = {
            BLOCK: 'ðŸ”´',
            WARN: 'ðŸŸ¡',
            CLEAR: 'ðŸŸ¢'
          };

          // Parse the diff to find valid line numbers per file (lines visible in the diff)
          // Also detect .not() on newly added lines
          const diffContent = fs.readFileSync('/tmp/pr.diff', 'utf8');
          const validLines = {};  // { "path/to/file": Set([line numbers]) }
          const dotNotLines = [];  // { file, line } for added lines containing .not()
          let currentFile = null;
          let newLineNum = 0;
          for (const line of diffContent.split('\n')) {
            const fileMatch = line.match(/^\+\+\+ b\/(.+)/);
            if (fileMatch) {
              currentFile = fileMatch[1];
              if (!validLines[currentFile]) validLines[currentFile] = new Set();
              continue;
            }
            const hunkMatch = line.match(/^@@ -\d+(?:,\d+)? \+(\d+)(?:,\d+)? @@/);
            if (hunkMatch) {
              newLineNum = parseInt(hunkMatch[1], 10);
              continue;
            }
            if (currentFile && !line.startsWith('---') && !line.startsWith('diff ')) {
              if (line.startsWith('+') || line.startsWith(' ')) {
                validLines[currentFile].add(newLineNum);
                // Detect .not() on added lines only (not context lines)
                if (line.startsWith('+') && line.match(/\.not\(\)/)) {
                  dotNotLines.push({ file: currentFile, line: newLineNum });
                }
                newLineNum++;
              } else if (line.startsWith('-')) {
                // Deleted lines don't increment the new file line counter
              } else {
                newLineNum++;
              }
            }
          }

          // Find the closest valid diff line for a file
          function closestValidLine(filePath, targetLine) {
            const lines = validLines[filePath];
            if (!lines || lines.size === 0) return null;
            const sorted = [...lines].sort((a, b) => a - b);
            let best = sorted[0];
            for (const l of sorted) {
              if (Math.abs(l - targetLine) < Math.abs(best - targetLine)) best = l;
            }
            return best;
          }

          // Collect all critical issues from deep reviews
          const allIssues = [];
          for (const file of analysisJson.files || []) {
            for (const hunk of file.hunks || []) {
              if (hunk.aiReview && hunk.aiReview.critical) {
                for (const issue of hunk.aiReview.critical) {
                  allIssues.push({
                    file: file.filename,
                    line: issue.line,
                    type: issue.type,
                    issue: issue.issue,
                    diffHash: hunk.hunk.fileDiffHash,
                    friendlySuggestion: issue.friendlySuggestion || issue.issue,
                    source: 'deep-review'
                  });
                }
              }
            }
          }

          // Collect adversarial findings
          const adversarialFindings = analysisJson.adversarialFindings || [];
          for (const finding of adversarialFindings) {
            allIssues.push({
              file: finding.filename,
              line: finding.line,
              type: finding.type,
              issue: finding.issue,
              friendlySuggestion: finding.friendlySuggestion || finding.issue,
              source: 'adversarial',
              persona: finding.persona
            });
          }

          // Get verdict
          const verdict = analysisJson.verdict || null;
          
          // Get PR summary from triage
          const prSummary = (analysisJson.triage && analysisJson.triage.prSummary) || '';
          
          if (allIssues.length === 0) {
            // Post "no issues" message with verdict
            const marker = '<!-- reviewpal -->';
            let noIssuesMsg = `${marker}\n\n`;

            // Show verdict at top
            if (verdict) {
              const vEmoji = VERDICT_EMOJI[verdict.verdict] || 'âšª';
              noIssuesMsg += `## ${vEmoji} Verdict: ${verdict.verdict}\n\n`;
              noIssuesMsg += `> ${verdict.reason}\n\n---\n\n`;
            }

            if (prSummary) {
              noIssuesMsg += `## ðŸ“‹ What is this PR about\n\n${prSummary}\n\n---\n\n`;
            }

            if (!verdict) {
              noIssuesMsg += `âœ… **No critical issues found**`;
            }
            
            // Check for existing comment
            const { data: comments } = await github.rest.issues.listComments({
              owner: context.repo.owner,
              repo: context.repo.repo,
              issue_number: context.issue.number
            });
            
            const botComment = comments.find(c => c.body && c.body.includes(marker));
            
            if (botComment) {
              await github.rest.issues.updateComment({
                owner: context.repo.owner,
                repo: context.repo.repo,
                comment_id: botComment.id,
                body: noIssuesMsg
              });
            } else {
              await github.rest.issues.createComment({
                owner: context.repo.owner,
                repo: context.repo.repo,
                issue_number: context.issue.number,
                body: noIssuesMsg
              });
            }
            
            console.log('No critical issues found - posted confirmation');
          }

          // Post chef's kiss on every .not() in added lines
          const headSha = context.payload.pull_request.head.sha;
          if (dotNotLines.length > 0) {
            console.log(`Found ${dotNotLines.length} .not() usage(s) - posting chef's kiss`);
            for (const dot of dotNotLines) {
              try {
                await github.rest.pulls.createReviewComment({
                  owner: context.repo.owner,
                  repo: context.repo.repo,
                  pull_number: context.issue.number,
                  body: 'ðŸ¤Œ',
                  commit_id: headSha,
                  path: dot.file,
                  line: dot.line,
                  side: 'RIGHT'
                });
              } catch (e) {
                console.log(`Failed to chef-kiss ${dot.file}:${dot.line}:`, e.message);
              }
            }
          }

          if (allIssues.length === 0) return;

          // Post inline comments on each line, snapping to nearest valid diff line
          const commentLinks = [];
          const failedIssues = [];

          for (const item of allIssues) {
            const diffLine = closestValidLine(item.file, item.line);
            if (!diffLine) {
              console.log(`No valid diff lines for ${item.file}, will include in summary`);
              failedIssues.push(item);
              continue;
            }
            if (Math.abs(diffLine - item.line) > 0) {
              console.log(`Snapped ${item.file}:${item.line} -> ${diffLine} (nearest diff line)`);
            }
            try {
              let commentBody = `${EMOJI_MAP[item.type] || 'âš ï¸'} **${item.type.toUpperCase()}**: ${item.friendlySuggestion}`;
              if (item.source === 'adversarial' && item.persona) {
                commentBody += `\n\n_Found by ${item.persona}_`;
              }

              const comment = await github.rest.pulls.createReviewComment({
                owner: context.repo.owner,
                repo: context.repo.repo,
                pull_number: context.issue.number,
                body: commentBody,
                commit_id: headSha,
                path: item.file,
                line: diffLine,
                side: 'RIGHT'
              });

              const commentId = comment.data.id;
              const commentAnchor = `#discussion_r${commentId}`;

              commentLinks.push({
                type: item.type,
                url: commentAnchor,
                file: item.file,
                line: item.line
              });
            } catch (e) {
              console.log(`Failed to comment on ${item.file}:${diffLine}:`, e.message);
              failedIssues.push(item);
            }
          }
          
          // Build summary
          let summary = '';

          // Show verdict at top
          if (verdict) {
            const vEmoji = VERDICT_EMOJI[verdict.verdict] || 'âšª';
            summary += `## ${vEmoji} Verdict: ${verdict.verdict}\n\n`;
            summary += `> ${verdict.reason}\n\n---\n\n`;
          }

          // Add PR summary with styling
          if (prSummary) {
            summary += `## ðŸ“‹ What is this PR about\n\n`;
            summary += `${prSummary}\n\n`;
            summary += `---\n\n`;
          }

          if (commentLinks.length > 0) {
            // Build summary with numbered links to inline comments
            const issuesByType = {};
            let counter = 1;

            for (const item of commentLinks) {
              if (!issuesByType[item.type]) issuesByType[item.type] = [];
              issuesByType[item.type].push({
                num: counter++,
                url: item.url,
                file: item.file,
                line: item.line
              });
            }

            summary += `## ðŸ’¡ Suggestions\n\n`;
            summary += `| Category | Count | Details |\n`;
            summary += `|----------|-------|----------|\n`;

            const severityOrder = ['security', 'crash', 'data-loss', 'performance', 'regression', 'logic'];
            const sortedTypes = Object.keys(issuesByType).sort((a, b) => {
              return severityOrder.indexOf(a) - severityOrder.indexOf(b);
            });

            for (const type of sortedTypes) {
              const items = issuesByType[type];
              const emoji = EMOJI_MAP[type] || 'âš ï¸';
              const links = items.map(i => `[${i.num}](${i.url})`).join(' ');
              const typeLabel = type.toUpperCase().replace('-', ' ');
              summary += `| ${emoji} **${typeLabel}** | ${items.length} | ${links} |\n`;
            }
          } else {
            summary += `## ðŸ’¡ Suggestions\n\n`;
          }

          // Always include issues that couldn't be posted inline
          if (failedIssues.length > 0) {
            if (commentLinks.length > 0) {
              summary += `\n### Additional findings\n\n`;
            }
            for (const item of failedIssues) {
              const emoji = EMOJI_MAP[item.type] || 'âš ï¸';
              summary += `${emoji} **${item.type.toUpperCase()}** in \`${item.file}:${item.line}\`\n`;
              summary += `> ${item.friendlySuggestion}\n\n`;
            }
          }
          
          // Post or update summary comment
          const marker = '<!-- reviewpal -->';
          const { data: comments } = await github.rest.issues.listComments({
            owner: context.repo.owner,
            repo: context.repo.repo,
            issue_number: context.issue.number
          });
          
          const botComment = comments.find(c => c.body && c.body.includes(marker));
          const body = `${marker}\n\n${summary}`;
          
          if (botComment) {
            await github.rest.issues.updateComment({
              owner: context.repo.owner,
              repo: context.repo.repo,
              comment_id: botComment.id,
              body
            });
          } else {
            await github.rest.issues.createComment({
              owner: context.repo.owner,
              repo: context.repo.repo,
              issue_number: context.issue.number,
              body
            });
          }
    
